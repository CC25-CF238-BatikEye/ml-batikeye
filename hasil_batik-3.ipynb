{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"PUfchCA79z39"},"outputs":[],"source":["import os\n","import tensorflow as tf\n","import numpy as np\n","from tensorflow.keras.applications import MobileNetV2\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, BatchNormalization\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nBovCD2iHXgJ","outputId":"e1ea847c-e258-4076-b769-736c1037cb7a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xV1L_AXT-Ars"},"outputs":[],"source":["base_dir = '/content/drive/MyDrive/Indonesia_Batik'\n","train_dir = os.path.join(base_dir, 'train')\n","val_dir = os.path.join(base_dir, 'valid')\n","test_dir = os.path.join(base_dir, 'test')"]},{"cell_type":"markdown","metadata":{"id":"92AFj1lMmyMj"},"source":["# Image Aug"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vw6EEQU4-H50","outputId":"e3051e43-40e7-40c2-f2ae-e7a2cf874c64"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py:1054: UserWarning: This ImageDataGenerator specifies `zca_whitening` which overrides setting of`featurewise_std_normalization`.\n","  warnings.warn(\n"]}],"source":["train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=40,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    brightness_range=[0.8, 1.2],\n","    featurewise_center=True,\n","    featurewise_std_normalization=True,\n","    zca_whitening=True,\n","    channel_shift_range=20,\n","    fill_mode=\"nearest\"\n",")\n","\n","val_datagen = ImageDataGenerator(rescale=1./255)\n","test_datagen = ImageDataGenerator(rescale=1./255)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XkBc-qjG-NzO","outputId":"c61b94f0-454c-48a4-d9fe-dc9d944daf88"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 1830 images belonging to 13 classes.\n","Found 260 images belonging to 13 classes.\n","Found 130 images belonging to 13 classes.\n"]}],"source":["train_generator = train_datagen.flow_from_directory(\n","    train_dir,\n","    target_size=(150, 150),\n","    batch_size=32,\n","    class_mode='categorical'\n",")\n","\n","val_generator = val_datagen.flow_from_directory(\n","    val_dir,\n","    target_size=(150, 150),\n","    batch_size=32,\n","    class_mode='categorical'\n",")\n","\n","test_generator = test_datagen.flow_from_directory(\n","    test_dir,\n","    target_size=(150, 150),\n","    batch_size=32,\n","    class_mode='categorical',\n","    shuffle=False\n",")"]},{"cell_type":"markdown","metadata":{"id":"LLjhAux7jEtr"},"source":["# Modelling"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TlwfoWoK-Qil","outputId":"b5316d72-2950-405e-de70-20ab0cf10c5b"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-6-406ca16ee771>:1: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","  base_model = MobileNetV2(\n"]},{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n","\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"]}],"source":["base_model = MobileNetV2(\n","    input_shape=(150, 150, 3),\n","    include_top=False,\n","    weights=\"imagenet\"\n",")\n","base_model.trainable = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZsVXOs-l-TN1"},"outputs":[],"source":["model = Sequential([\n","    base_model,\n","    GlobalAveragePooling2D(),\n","    BatchNormalization(),\n","    Dropout(0.5),\n","    Dense(128, activation=\"relu\"),\n","    BatchNormalization(),\n","    Dropout(0.3),\n","    Dense(train_generator.num_classes, activation=\"softmax\")\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IJEt1Vrl-vm4"},"outputs":[],"source":["lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n","    initial_learning_rate=1e-3,\n","    decay_steps=10000,\n","    decay_rate=0.9\n",")\n","optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vDJpjPQw-yGa"},"outputs":[],"source":["model.compile(\n","    optimizer=optimizer,\n","    loss=\"categorical_crossentropy\",\n","    metrics=[\"accuracy\"]\n",")"]},{"cell_type":"markdown","metadata":{"id":"-PmPBY0aoF8P"},"source":["# Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"lVp23SMi-0nK","outputId":"b1719538-3b98-4d01-d558-e3d534fcba22"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py:1263: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py:1286: UserWarning: This ImageDataGenerator specifies `zca_whitening`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m663s\u001b[0m 11s/step - accuracy: 0.2933 - loss: 2.4700 - val_accuracy: 0.6923 - val_loss: 1.0848\n","Epoch 2/50\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - accuracy: 0.6330 - loss: 1.1365 - val_accuracy: 0.7308 - val_loss: 0.8514\n","Epoch 3/50\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.6911 - loss: 0.9174 - val_accuracy: 0.7577 - val_loss: 0.7807\n","Epoch 4/50\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 1s/step - accuracy: 0.7488 - loss: 0.7443 - val_accuracy: 0.7577 - val_loss: 0.7203\n","Epoch 5/50\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.7829 - loss: 0.6662 - val_accuracy: 0.8000 - val_loss: 0.6421\n","Epoch 6/50\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.8086 - loss: 0.6336 - val_accuracy: 0.7846 - val_loss: 0.6788\n","Epoch 7/50\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - accuracy: 0.8047 - loss: 0.5503 - val_accuracy: 0.7846 - val_loss: 0.6507\n","Epoch 8/50\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.8127 - loss: 0.5339 - val_accuracy: 0.8038 - val_loss: 0.6233\n","Epoch 9/50\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - accuracy: 0.8229 - loss: 0.5576 - val_accuracy: 0.8115 - val_loss: 0.6278\n","Epoch 10/50\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - accuracy: 0.8285 - loss: 0.4955 - val_accuracy: 0.8308 - val_loss: 0.5879\n","Epoch 11/50\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - accuracy: 0.8345 - loss: 0.4722 - val_accuracy: 0.8077 - val_loss: 0.5855\n","Epoch 12/50\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - accuracy: 0.8551 - loss: 0.4357 - val_accuracy: 0.8115 - val_loss: 0.6056\n","Epoch 13/50\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - accuracy: 0.8308 - loss: 0.4784 - val_accuracy: 0.8154 - val_loss: 0.5895\n","Epoch 14/50\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.8620 - loss: 0.4300 - val_accuracy: 0.7962 - val_loss: 0.5753\n","Epoch 15/50\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - accuracy: 0.8690 - loss: 0.4204 - val_accuracy: 0.8115 - val_loss: 0.5706\n","Epoch 1/30\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 3s/step - accuracy: 0.6400 - loss: 1.1886 - val_accuracy: 0.5385 - val_loss: 2.4799\n","Epoch 2/30\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 2s/step - accuracy: 0.8575 - loss: 0.4296 - val_accuracy: 0.5308 - val_loss: 3.2217\n","Epoch 3/30\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 2s/step - accuracy: 0.8857 - loss: 0.3605 - val_accuracy: 0.5654 - val_loss: 2.5058\n","Epoch 4/30\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 2s/step - accuracy: 0.9136 - loss: 0.2652 - val_accuracy: 0.5308 - val_loss: 2.9648\n","Epoch 5/30\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 2s/step - accuracy: 0.9156 - loss: 0.2547 - val_accuracy: 0.6385 - val_loss: 1.9614\n","Epoch 6/30\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 2s/step - accuracy: 0.9410 - loss: 0.1714 - val_accuracy: 0.6500 - val_loss: 1.7183\n","Epoch 7/30\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 2s/step - accuracy: 0.9634 - loss: 0.1289 - val_accuracy: 0.6731 - val_loss: 1.6933\n","Epoch 8/30\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 2s/step - accuracy: 0.9694 - loss: 0.0973 - val_accuracy: 0.6962 - val_loss: 1.6781\n","Epoch 9/30\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 2s/step - accuracy: 0.9522 - loss: 0.1459 - val_accuracy: 0.7269 - val_loss: 1.3663\n","Epoch 10/30\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 2s/step - accuracy: 0.9816 - loss: 0.0780 - val_accuracy: 0.7423 - val_loss: 1.2486\n","Epoch 11/30\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 2s/step - accuracy: 0.9832 - loss: 0.0665 - val_accuracy: 0.7731 - val_loss: 0.9783\n","Epoch 12/30\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 2s/step - accuracy: 0.9724 - loss: 0.0867 - val_accuracy: 0.8308 - val_loss: 0.7466\n","Epoch 13/30\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 2s/step - accuracy: 0.9838 - loss: 0.0713 - val_accuracy: 0.8000 - val_loss: 0.7941\n","Epoch 14/30\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 2s/step - accuracy: 0.9840 - loss: 0.0636 - val_accuracy: 0.8808 - val_loss: 0.5333\n","Epoch 15/30\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 2s/step - accuracy: 0.9764 - loss: 0.0785 - val_accuracy: 0.8462 - val_loss: 0.6384\n","Epoch 16/30\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 2s/step - accuracy: 0.9744 - loss: 0.0898 - val_accuracy: 0.8962 - val_loss: 0.5332\n","Epoch 17/30\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 2s/step - accuracy: 0.9793 - loss: 0.0709 - val_accuracy: 0.8962 - val_loss: 0.5580\n","Epoch 18/30\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 2s/step - accuracy: 0.9855 - loss: 0.0442 - val_accuracy: 0.8846 - val_loss: 0.5048\n","Epoch 19/30\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 2s/step - accuracy: 0.9869 - loss: 0.0539 - val_accuracy: 0.9077 - val_loss: 0.4555\n","Epoch 20/30\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 2s/step - accuracy: 0.9883 - loss: 0.0538 - val_accuracy: 0.9115 - val_loss: 0.4397\n","Epoch 21/30\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 2s/step - accuracy: 0.9755 - loss: 0.0809 - val_accuracy: 0.9038 - val_loss: 0.4377\n","Epoch 22/30\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 2s/step - accuracy: 0.9789 - loss: 0.0735 - val_accuracy: 0.8808 - val_loss: 0.4468\n","Epoch 23/30\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 2s/step - accuracy: 0.9913 - loss: 0.0415 - val_accuracy: 0.9038 - val_loss: 0.3990\n","Epoch 24/30\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 2s/step - accuracy: 0.9848 - loss: 0.0477 - val_accuracy: 0.9192 - val_loss: 0.3516\n","Epoch 25/30\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 2s/step - accuracy: 0.9897 - loss: 0.0413 - val_accuracy: 0.9077 - val_loss: 0.3673\n","Epoch 26/30\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 2s/step - accuracy: 0.9920 - loss: 0.0421 - val_accuracy: 0.9385 - val_loss: 0.3331\n","Epoch 27/30\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 2s/step - accuracy: 0.9906 - loss: 0.0515 - val_accuracy: 0.9385 - val_loss: 0.3136\n","Epoch 28/30\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 2s/step - accuracy: 0.9869 - loss: 0.0516 - val_accuracy: 0.9385 - val_loss: 0.2965\n","Epoch 29/30\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 2s/step - accuracy: 0.9928 - loss: 0.0320 - val_accuracy: 0.9500 - val_loss: 0.2781\n","Epoch 30/30\n","\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 2s/step - accuracy: 0.9937 - loss: 0.0299 - val_accuracy: 0.9462 - val_loss: 0.2590\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5s/step - accuracy: 0.9590 - loss: 0.1430\n","Final Test Accuracy: 94.62%\n","Final Test Loss: 0.1988\n"]}],"source":["early_stopping = tf.keras.callbacks.EarlyStopping(\n","    monitor=\"val_accuracy\",\n","    patience=15,\n","    restore_best_weights=True,\n","    min_delta=0.001,\n","    mode=\"max\",\n","    baseline=0.92\n",")\n","\n","history = model.fit(\n","    train_generator,\n","    epochs=50,\n","    validation_data=val_generator,\n","    callbacks=[early_stopping]\n",")\n","\n","base_model.trainable = True\n","for layer in base_model.layers[:30]:\n","    layer.trainable = False\n","\n","\n","# Re-compile untuk Fine-Tuning\n","\n","optimizer = tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9)\n","model.compile(\n","    optimizer=optimizer,\n","    loss=\"categorical_crossentropy\",\n","    metrics=[\"accuracy\"]\n",")\n","\n","\n","# Training Kedua (Fine-Tuning)\n","history_finetune = model.fit(\n","    train_generator,\n","    epochs=30,\n","    validation_data=val_generator\n",")\n","\n","\n","# Evaluasi Model\n","\n","test_loss, test_acc = model.evaluate(test_generator)\n","print(f\"Final Test Accuracy: {test_acc * 100:.2f}%\")\n","print(f\"Final Test Loss: {test_loss:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DT_e3Y8sIJWS"},"outputs":[],"source":["from sklearn.metrics import classification_report\n","import numpy as np\n","\n","y_pred_probs = model.predict(test_generator)\n","y_pred = np.argmax(y_pred_probs, axis=1)\n","y_true = test_generator.classes\n","\n","class_names = list(test_generator.class_indices.keys())\n","\n","print(\"Classification Report:\\n\")\n","print(classification_report(y_true, y_pred, target_names=class_names))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rWtI9kPmJrG4"},"outputs":[],"source":["class_labels = [\n","    'Bokor-Kencono',\n","    'Kawung',\n","    'Mega-Mendung',\n","    'Parang',\n","    'Sekar-Jagad',\n","    'Sidoluhur',\n","    'Sidomukti',\n","    'Sidomulyo',\n","    'Srikaton',\n","    'Tribusono',\n","    'Truntum',\n","    'Wahyu-Tumurun',\n","    'Wirasat'\n","]\n","\n","# Informasi budaya untuk masing-masing motif\n","batik_info = {\n","    \"bokor_kencono\": {\n","    \"name\": \"Batik Bokor Kencono\",\n","    \"description\": \"Melambangkan kemakmuran dan kehormatan dalam budaya Jawa.\",\n","    \"origin\": \"Surakarta\"\n","  },\n","  \"kawung\": {\n","    \"name\": \"Batik Kawung\",\n","    \"description\": \"Motif geometris berbentuk bulatan menyerupai buah kawung (aren), melambangkan kesucian dan keadilan.\",\n","    \"origin\": \"Yogyakarta\"\n","  },\n","  \"mega_mendung\": {\n","    \"name\": \"Batik Mega Mendung\",\n","    \"description\": \"Bermotif awan bergelombang, melambangkan ketenangan dan kesabaran.\",\n","    \"origin\": \"Cirebon\"\n","  },\n","  \"parang\": {\n","    \"name\": \"Batik Parang\",\n","    \"description\": \"Motif diagonal bersambung menyerupai ombak, melambangkan kekuatan dan perjuangan.\",\n","    \"origin\": \"Yogyakarta\"\n","  },\n","  \"sekar_jagad\": {\n","    \"name\": \"Batik Sekar Jagad\",\n","    \"description\": \"Motif peta bunga dunia, melambangkan keindahan dan keragaman budaya.\",\n","    \"origin\": \"Yogyakarta dan Surakarta\"\n","  },\n","  \"sidoluhur\": {\n","    \"name\": \"Batik Sidoluhur\",\n","    \"description\": \"Melambangkan harapan menjadi pribadi yang terhormat dan bermartabat.\",\n","    \"origin\": \"Yogyakarta\"\n","  },\n","  \"sidomukti\": {\n","    \"name\": \"Batik Sidomukti\",\n","    \"description\": \"Motif ini menyimbolkan kemakmuran dan kebahagiaan yang berkelanjutan.\",\n","    \"origin\": \"Surakarta\"\n","  },\n","  \"sidomulyo\": {\n","    \"name\": \"Batik Sidomulyo\",\n","    \"description\": \"Mengandung harapan akan kehidupan yang mulia dan sejahtera.\",\n","    \"origin\": \"Surakarta\"\n","  },\n","  \"srikaton\": {\n","    \"name\": \"Batik Srikaton\",\n","    \"description\": \"Motif ini melambangkan kemuliaan dan kemakmuran yang agung.\",\n","    \"origin\": \"Surakarta\"\n","  },\n","  \"tribusono\": {\n","    \"name\": \"Batik Tribusono\",\n","    \"description\": \"Motif klasik dengan nilai historis yang tinggi, melambangkan keselarasan.\",\n","    \"origin\": \"Surakarta\"\n","  },\n","  \"truntum\": {\n","    \"name\": \"Batik Truntum\",\n","    \"description\": \"Melambangkan cinta yang tumbuh kembali dan tak pernah padam, sering dipakai dalam pernikahan.\",\n","    \"origin\": \"Surakarta\"\n","  },\n","  \"wahyu_tumurun\": {\n","    \"name\": \"Batik Wahyu Tumurun\",\n","    \"description\": \"Melambangkan harapan akan turunnya wahyu (berkah) dan kemuliaan dari Tuhan.\",\n","    \"origin\": \"Surakarta\"\n","  },\n","  \"wirasat\": {\n","    \"name\": \"Batik Wirasat\",\n","    \"description\": \"Motif ini menyiratkan pesan dan harapan bijak dari orang tua kepada anaknya.\",\n","    \"origin\": \"Surakarta\"\n","    }\n","}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WCCBdtJJK7q5"},"outputs":[],"source":["def predict_batik_from_upload(model, file_path, class_labels, batik_info, threshold=0.5):\n","    # Preprocessing gambar\n","    img = tf.keras.preprocessing.image.load_img(file_path, target_size=(150, 150))\n","    img_array = tf.keras.preprocessing.image.img_to_array(img)\n","    img_array = tf.expand_dims(img_array, axis=0) / 255.0\n","\n","    # Prediksi model\n","    predictions = model.predict(img_array)\n","    confidence = float(np.max(predictions))\n","    predicted_class_idx = int(np.argmax(predictions))\n","\n","    # Cek confidence threshold\n","    if confidence < threshold:\n","        return {\n","            \"prediction\": \"Motif tidak dikenali\",\n","            \"confidence\": confidence,\n","            \"info\": None\n","        }\n","\n","    # Ambil nama class dan info budaya\n","    class_name = class_labels[predicted_class_idx]\n","    info_key = class_name.lower().replace(\"-\", \"_\").replace(\" \", \"_\")\n","    info = batik_info.get(info_key, None)\n","\n","    return {\n","        \"prediction\": class_name,\n","        \"confidence\": confidence,\n","        \"info\": info\n","    }\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1zn27B1tK8sb"},"outputs":[],"source":["image_path = '/content/drive/MyDrive/Indonesia_Batik/test/Parang/-1-_jpg.rf.b6a04b8af468e4ad447b8725a0110e43.jpg'  # Change this to your actual image path\n","\n","result = predict_batik_from_upload(\n","    model=model,\n","    file_path=image_path,\n","    class_labels=class_labels,\n","    batik_info=batik_info,\n","    threshold=0.5\n",")\n","\n","print(result)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zOGkWznW8EZL"},"outputs":[],"source":["def predict_batik_from_directory(model, dir_path, class_labels, batik_info, threshold=0.5):\n","    results = []\n","    for filename in os.listdir(dir_path):\n","        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n","            file_path = os.path.join(dir_path, filename)\n","            try:\n","                # Use the original prediction function\n","                result = predict_batik_from_upload(model, file_path, class_labels, batik_info, threshold)\n","                results.append((filename, result))\n","            except Exception as e:\n","                print(f\"Error processing {filename}: {str(e)}\")\n","    return results\n","\n","\n","# directory_results = predict_batik_from_directory(model, '/content/drive/MyDrive/Indonesia_Batik/test/Parang', class_labels, batik_info)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jUYzZdS2-dXz"},"outputs":[],"source":["from tensorflow.keras.preprocessing import image\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","img_path = '/content/drive/MyDrive/Indonesia_Batik/test/Parang/-1-_jpg.rf.b6a04b8af468e4ad447b8725a0110e43.jpg'\n","\n","# Load dan preprocess gambar\n","img = image.load_img(img_path, target_size=(160, 160))\n","img_array = image.img_to_array(img) / 255.0\n","img_array = np.expand_dims(img_array, axis=0)\n","\n","# Prediksi\n","prediction = model.predict(img_array)\n","predicted_class = list(train_generator.class_indices.keys())[np.argmax(prediction)]\n","\n","# Visualisasi\n","plt.imshow(img)\n","plt.title(f\"Predicted: {predicted_class}\")\n","plt.axis('off')\n","plt.show()\n","\n","result = predict_batik_from_upload(\n","    model=model,\n","    file_path=image_path,\n","    class_labels=class_labels,\n","    batik_info=batik_info,\n","    threshold=0.5\n",")\n","\n","print(result)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6ZiJArATbogv"},"outputs":[],"source":["import tensorflow as tf\n","\n","# Simpan model ke format .h5\n","model.save('model_batik.h5')\n","\n","# Simpan model ke format .keras\n","model.save('model_batik.keras')\n","\n","print(\"Model berhasil disimpan dalam format .h5 dan .keras!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uEWgewc_wSqE"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Simpan ke Google Drive\n","model.save('/content/drive/MyDrive/model_batik.h5')\n","model.save('/content/drive/MyDrive/model_batik.keras')\n","\n","print(\"Model berhasil disimpan di Google Drive!\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}